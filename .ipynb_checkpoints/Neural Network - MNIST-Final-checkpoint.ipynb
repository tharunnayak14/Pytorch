{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47af8e66",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e43edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.532501Z",
     "start_time": "2021-07-17T10:38:10.361586Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # all nn modules\n",
    "import torch.optim as optim # optimization algorithms\n",
    "import torch.nn.functional as F # activation functions like relu, tanh (all functions with no parameters)\n",
    "from torch.utils.data import DataLoader # helps with daata\n",
    "import torchvision.datasets as datasets # has many data sets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2519a",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449f52d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.546333Z",
     "start_time": "2021-07-17T10:38:11.535360Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "# how many data examples we pass in one iteration\n",
    "batch_size = 64\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398e4343",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65529476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.594215Z",
     "start_time": "2021-07-17T10:38:11.551323Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A:\\Anacond\\envs\\deeplearning\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = \"data/\", train=True, transform=transforms.ToTensor())\n",
    "# We pass the Dataset as an argument to DataLoader\n",
    "# This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading\n",
    "# Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels\n",
    "train_loader = DataLoader(dataset=train_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c44744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.609248Z",
     "start_time": "2021-07-17T10:38:11.596465Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root = \"data/\", train=False, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a07e07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.655788Z",
     "start_time": "2021-07-17T10:38:11.611243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8a7d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.688363Z",
     "start_time": "2021-07-17T10:38:11.657764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([0, 4, 1, 7, 3, 9, 5, 5, 0, 9, 2, 6, 8, 0, 5, 0, 3, 5, 4, 7, 2, 7, 5, 6,\n",
      "        6, 4, 6, 9, 7, 7, 2, 0, 4, 1, 6, 1, 5, 4, 7, 8, 2, 6, 2, 4, 1, 4, 4, 8,\n",
      "        7, 1, 0, 2, 2, 8, 7, 5, 9, 1, 7, 6, 8, 8, 2, 8])]\n"
     ]
    }
   ],
   "source": [
    "# for iteration we use loaded data\n",
    "for data in train_loader: \n",
    "    # 64 digits and 64 labels\n",
    "    print(data)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c98565bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.702324Z",
     "start_time": "2021-07-17T10:38:11.693342Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = data[0][0], data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979373ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.733473Z",
     "start_time": "2021-07-17T10:38:11.707908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275,\n",
      "          0.6941, 0.9961, 0.8314, 0.4745, 0.1255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.6980, 0.9725,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.4824, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.2353, 0.6784, 0.9922, 0.9961,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.7804, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2510, 0.3176, 0.4000, 0.9373, 0.9922, 0.9922, 0.9961,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.7804, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
      "          0.7059, 0.9490, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9961,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.8392, 0.0824, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9804, 0.7804, 0.7882,\n",
      "          0.7804, 0.8588, 0.9922, 0.9922, 0.9922, 0.6980, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8941,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.8941, 0.5137, 0.0000, 0.0000,\n",
      "          0.0000, 0.1176, 0.8863, 0.9922, 0.9922, 0.9451, 0.3373, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5569,\n",
      "          0.9922, 0.9922, 0.9922, 0.9765, 0.3255, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.5843, 0.5294, 0.9922, 0.9922, 0.9529, 0.2667,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6745,\n",
      "          0.9922, 0.9922, 0.9922, 0.8431, 0.0196, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1137, 0.8431, 0.9922, 0.9922, 0.4471,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9451,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.3647, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.4588, 0.9922, 0.9922, 0.9412,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6706, 0.9961,\n",
      "          0.9961, 0.8745, 0.6235, 0.9961, 0.9961, 0.6667, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6863, 1.0000, 1.0000,\n",
      "          0.4745, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9451, 0.9922,\n",
      "          0.9922, 0.2314, 0.0118, 0.1333, 0.5725, 0.2667, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6824, 0.9922, 0.9686,\n",
      "          0.2706, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9451, 0.9922,\n",
      "          0.9922, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3843, 0.9608, 0.9922, 0.9412,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4039, 0.9843, 0.9922,\n",
      "          0.7255, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.7333, 0.9922, 0.9922, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9922, 0.9922,\n",
      "          0.7608, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0863, 0.6784, 0.9412, 0.9922, 0.9647, 0.3059,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.9569, 0.9922,\n",
      "          0.9922, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.6824, 0.8157, 0.9922, 0.9922, 0.9608, 0.4235, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8627, 0.9922,\n",
      "          0.9922, 0.9098, 0.6824, 0.6000, 0.1608, 0.1608, 0.1608, 0.6863,\n",
      "          0.8118, 0.9922, 0.9922, 0.9922, 0.8745, 0.4275, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.8745,\n",
      "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 1.0000,\n",
      "          0.9922, 0.9922, 0.9608, 0.4745, 0.0980, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
      "          0.8588, 0.9804, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9725,\n",
      "          0.9412, 0.7451, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3725, 0.4706, 0.8275, 0.9922, 0.9647, 0.4706, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bcd3f6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:11.749449Z",
     "start_time": "2021-07-17T10:38:11.738460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b8701bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:12.001353Z",
     "start_time": "2021-07-17T10:38:11.754417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20f14009490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.imshow(data[0][0])\n",
    "# (1, 28, 28) so plt.imshow() wont work\n",
    "# so use .view(28, 28)\n",
    "plt.imshow(data[0][0].view(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f5bd8",
   "metadata": {},
   "source": [
    "# To find whether the classes are balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07de9a97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:18.512462Z",
     "start_time": "2021-07-17T10:38:12.003322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in train_loader:\n",
    "    Xs, ys =  data\n",
    "    for y in ys:\n",
    "        # increase the count of corresponding class by 1\n",
    "        counter_dict[int(y)] +=1\n",
    "        total +=1\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc597be4",
   "metadata": {},
   "source": [
    "# We can see the classes are well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2fb53b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:18.528514Z",
     "start_time": "2021-07-17T10:38:18.515549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.872\n",
      "1: 11.237\n",
      "2: 9.930\n",
      "3: 10.218\n",
      "4: 9.737\n",
      "5: 9.035\n",
      "6: 9.863\n",
      "7: 10.442\n",
      "8: 9.752\n",
      "9: 9.915\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    # percentages of class in the dataet\n",
    "    print(f\"{i}: {counter_dict[i]/total*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c66ac1",
   "metadata": {},
   "source": [
    "# Create a fully connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08086c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:18.559323Z",
     "start_time": "2021-07-17T10:38:18.534496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# inherits from the nn module\n",
    "# Our first linear layer take input_size, in this case 784 nodes to 512\n",
    "# and our second linear layer takes 512 to the num_classes we have, in this case 10.\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        # input layer\n",
    "        # fc1 = fully connected layer 1\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    # create a forward function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "print(NN(784, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f46be7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:18.621754Z",
     "start_time": "2021-07-17T10:38:18.565312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a6caa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:18.652208Z",
     "start_time": "2021-07-17T10:38:18.622703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28 images passes as 784\n",
    "# 10 for no of digits\n",
    "model = NN(784, 10)\n",
    "# 64 = no of examples (images) mini batch size\n",
    "x = torch.rand((64, 784))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7abd3",
   "metadata": {},
   "source": [
    "# Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a88f6a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:20.635125Z",
     "start_time": "2021-07-17T10:38:18.655185Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NN(input_size = input_size, num_classes = num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6a03d",
   "metadata": {},
   "source": [
    "# Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94bff568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:20.651164Z",
     "start_time": "2021-07-17T10:38:20.636095Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a21fd",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a9d8a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:20.666801Z",
     "start_time": "2021-07-17T10:38:20.652129Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # X has shape (64, 1, 28, 28)\n",
    "        # 64 training examples\n",
    "        # 1 as we are using gray scale images\n",
    "        # 28 * 28 height, width        \n",
    "        # we need to reshape this to (64, 784)\n",
    "        \n",
    "        X = X.reshape(X.shape[0],-1)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        # set gradients to zero for each batch, so it does not store back prop calculation from previous forward props\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            # print(f\"batch: {batch}, len:{len(X)}, current: {batch*len(X)}\")\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1ecde31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:20.682213Z",
     "start_time": "2021-07-17T10:38:20.667685Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X = X.reshape(X.shape[0],-1)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94af5a99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T10:38:52.139385Z",
     "start_time": "2021-07-17T10:38:20.683211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301552  [    0/60000]\n",
      "loss: 0.410534  [ 6400/60000]\n",
      "loss: 0.122795  [12800/60000]\n",
      "loss: 0.070232  [19200/60000]\n",
      "loss: 0.429095  [25600/60000]\n",
      "loss: 0.209324  [32000/60000]\n",
      "loss: 0.041764  [38400/60000]\n",
      "loss: 0.063368  [44800/60000]\n",
      "loss: 0.073759  [51200/60000]\n",
      "loss: 0.067457  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.122955 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.118960  [    0/60000]\n",
      "loss: 0.232684  [ 6400/60000]\n",
      "loss: 0.190240  [12800/60000]\n",
      "loss: 0.199486  [19200/60000]\n",
      "loss: 0.092651  [25600/60000]\n",
      "loss: 0.146022  [32000/60000]\n",
      "loss: 0.131783  [38400/60000]\n",
      "loss: 0.065467  [44800/60000]\n",
      "loss: 0.023156  [51200/60000]\n",
      "loss: 0.034701  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.086859 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.055964  [    0/60000]\n",
      "loss: 0.089168  [ 6400/60000]\n",
      "loss: 0.187666  [12800/60000]\n",
      "loss: 0.039032  [19200/60000]\n",
      "loss: 0.008296  [25600/60000]\n",
      "loss: 0.089376  [32000/60000]\n",
      "loss: 0.021206  [38400/60000]\n",
      "loss: 0.017889  [44800/60000]\n",
      "loss: 0.086955  [51200/60000]\n",
      "loss: 0.012849  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.082093 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
